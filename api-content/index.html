{"posts":[{"title":"[Summary][2020]Zero-Shot Learning[未完]","content":"Overview 监督学习的缺陷： 通过监督学习得到的学习器只能对训练数据覆盖的类的实例进行分类 缺乏对未知类的处理能力 可能出现未知类的原因： 目标类数量很大： 如CV方向中的对象识别。通常，人类可以识别的对象类别超过30000个，但为如此多的类分别收集足够多的标记实例是几乎不可能的。现有的数据集只能覆盖这些类中的一小部分，很多对象类没有标签实例。 目标类很稀有： 如细粒度的对象分类。如果需要识别不同品种的花朵种类，很难为每个特定的花卉品种收集足够的图像实例。对于很多稀有品种，我们找不到对应的带标签的实例。 目标类随时间变化： 如我们要识别某个品牌的产品实例。随着新样式、新产品的推陈出新，对于某些新产品，很难找到对应的带标签实例用于训练。 零样本学习： 目的：对属于未知类的实例进行分类处理 定义： 已知类集合：S={c_{i}^{s}}|i=1,\\dots,N_{s}}，其中cisc_{i}^{s}cis​是一个已知类 未知类集合：U=ciu∣i=1,…,NuU={c_{i}^{u}|i=1,\\dots,N_{u}}U=ciu​∣i=1,…,Nu​，其中ciuc_{i}^{u}ciu​是一个未知类 特征空间：XXX，通常为DDD维实数空间RDR^{D}RD 已知类中被标注的训练实例集合：Dtr=(xitr,yitr)∈X×Si=1NtrD^{tr}={(x_{i}^{tr},y_{i}^{tr})\\in X\\times S}_{i=1}^{N_{tr}}Dtr=(xitr​,yitr​)∈X×Si=1Ntr​​ 测试实例集合：Xte=xite∈Xi=1NteX^{te}={x_{i}^{te}\\in X}_{i=1}^{N_{te}}Xte=xite​∈Xi=1Nte​​ 测试实例对应类集合：Yte=yite∈Ui=1NteY^{te}={y_{i}^{te}\\in U}_{i=1}^{N_{te}}Yte=yite​∈Ui=1Nte​​ Zero-Shot Learning: 给予Dtr∈SD^{tr}\\in SDtr∈S，目的是为了学习得到能预测测试实例属于哪个未知类的分类器fu(⋅):X→Uf^{u}(\\cdot):X\\rightarrow Ufu(⋅):X→U 与少样本学习的异同： 零样本学习的一般思路通常是将训练实例DtrD^{tr}Dtr中包含的知识迁移到测试实例的分类任务中，而训练样本空间和测试样本空间是不相交的，因此，零样本学习其实是迁移学习的一个子领域。 在存在少量目标空间的标记实例的情况下，我们可以利用基于异构迁移学习的方法来尝试解决，但是在零样本学习中，因为根本没有属于目标空间（未知类）的标记实例，这使得现有的异构迁移学习方法表现不佳。 语义空间 在处理零样本学习问题时，由于没有属于未知类的标记实例可用，因此我们需要一些辅助信息。这类辅助信息应该包含有有关所有未知类的信息，以确保为每一个未知类提供相应的辅助信息；同时，辅助信息还应与特征空间中的实例相关，以确保辅助信息的可用性。 在现有作品中，涉及辅助信息的方法是受人类认识世界的方式启发的——我们可以借助语义背景知识来进行零样本学习。比如，只要知道“斑马看起来像马，而且它身上有条纹”，即使我们之前没有看到过斑马，我们也可以识别它。通常，零样本学习所涉及的辅助信息是一些语义信息，它们共同形成了一个既包含已知类，也包含未知类的空间。我们将这个空间成为语义空间。 与特征空间类似，语义空间一般也是实数空间，且每一个类都对应一个向量表示，称之为原型（prototype）。 定义： 语义空间：TTT，通常为一个MMM维的实数空间RMR^{M}RM 已知类的原型表示：ts∈Tt^{s}\\in Tts∈T表示csc^{s}cs对应的原型，其集合为Ts=tisi=1NsT^{s}={t^{s}_{i}}_{i=1}^{N_s}Ts=tis​i=1Ns​​ 未知类的原型表示：tu∈Tt^{u}\\in Ttu∈T表示cuc^{u}cu对应的原型，其集合为Tu=tiui=1NuT^{u}={t^{u}_{i}}_{i=1}^{N_u}Tu=tiu​i=1Nu​​ 原型函数：π(⋅):S⋃U→T\\pi(\\cdot):S\\bigcup U \\rightarrow Tπ(⋅):S⋃U→T 在零样本学习中，类原型TsT^{s}Ts和TuT^{u}Tu也会参与到分类器fu(⋅)f^{u}(\\cdot)fu(⋅)的获取过程中。 现有的模型中已经利用了各种语义空间，根据语义空间的构造方式，可以分为： 人工干预式语义空间 在这一类语义空间中，空间的每个维度都是为人所设计的。 属性空间 属性空间是由一组属性构成的语义空间。它们是零样本学习中使用最广泛的语义空间之一。 在属性空间中，描述类的各种属性的术语被定义为空间的属性。空间属性通常是与类属性相对应的短语或单词（如识别任务中的“毛色”、“栖息环境”等）。而这些空间属性将用于形成语义空间，每个维度都对应一个空间属性。 在动物识别任务中，考虑三个属性，“条纹”、“陆生”和“植食”三个属性。在这个空间中，“老虎类“对应的原型为$[1,1,0]$，”马类“对应的原型为$[0,1,1]$。 上述举例所得到的属性值都是二进制的，通常而言，这个属性值也可以是实数，表示程度或该类拥有这个属性的置信度。 词汇空间 词汇空间是一种由词汇信息构建的语义空间，它是基于已知类的类标签和能够提供语义信息的数据集的语义空间。这种数据集可以是一些结构化的词汇数据库，例如WordNet。 WordNet是普林斯顿大学开发的英语语料库，可以理解为就是一个词典。 最基本的，WordNet通过网状结构来组织词汇，将含义相近的词汇划分到一个组中。在这个网状结构之中，词汇与词汇之间的主要通过同义词连接在一起而形成了含义基本一致的group，称为synsets，也就是同义词形成的集合不同的synset之间的连接是通过conceptual relation连接到一起的。conceptual relation实际上包含了很多种关系 1.不同的synset通过上位词和下位词关系连接到一起。比如“树”可以和它的下位词“柳树”连接到一起，“柳树”可以连接它的下位词“垂柳”等，还可以是部分和整体的关系； 2.动词之间可以通过某方面的层层递进连接到一起，比如communicate-talk-whisper，通过音量的大小顺序连接，move-jog-run通过移动的快慢顺序连接； 3.动词之间也可以通过相互关联的动作连接在一起，比如buy-pay、success-try，虽然不是同义词，但是会经常同时发生，因此连接在一起，这里就会包含了因果关系，蕴含关系等； 4.形容词之间会将反义词进行连接，如wet-dry、young-old等，同时也会和它含义相似，但又不完全同义的词汇连接在一起； 5.副词大多数的含义和它相应的形容词含义相同； 6.词根相同的不同形态词之间会被连接到一起，如observe(verb)和observant(adjective)、observation、observatory(nouns)，在名词和动词构成的词对儿中，我们已经能够获得该名词相对于动词的具体含义了，比如sleeping_car是sleep的LOCATION 利用WordNet作为信息源，就能够构建多种结构的语义空间，如词汇的上下位关系、词汇之间的相似性、因果关系等。一般，我们可以计算WordNet中两个类cic_ici​和cjc_jcj​的距离关系来表示原型tit_iti​的第jjj个维度的值。 关键词空间 关键词空间是一种由每个类的文本描述中提取出的一组关键词所构成的语义空间。在关键词空间中，文本描述最常见的来源是网站文本，如Wikipedia等百科型网站和植物数据库等特定领域的专业性描述网站。除了预定义的网站外，这些文本内容还可以通过搜索引擎获得，通过对每个类名称的Google查询，获得描述该类的网页。 机器学习的语义空间 在这一类语义空间中，空间的维度不是人为设计的，每个类的原型是从某些机器学习模型的输出中获得的。在这些原型中，每个维度都没有明确的语义含义，相反，语义信息包含在整个原型中。用于提取原型的模型可以在其他问题中进行预训练，或者专门针对零样本学习问题进行训练。 标签嵌入空间 标签嵌入空间是一种通过对类标签做嵌入获得类原型的语义空间。这种空间的技术源自自然语言处理的词嵌入技术。在零样本学习中，每个类的标签都是单词或短语，嵌入过程中，语义相似的单词或短语被嵌入为临近的向量，而语义差距大的单词或短语则被嵌入为相距很远的向量。以此方法获得的嵌入向量便是语义空间的原型。 在现有作品中，采用了不同的嵌入技术，如：Word2Vec和Glove。此外，学习嵌入模型的语料库也包含一般的语料库（如Wikipedia）和特定的专业语料库（如Flickr）。 描述嵌入空间 描述嵌入空间是通过对类的文本描述做嵌入来获得类原型的语义空间。与人工干预式语义空间中的关键词空间类似，描述嵌入空间中的语义信息也来自于文本描述。 这两种方式的主要差异为：关键词空间通过提取文本描述中的关键词，并将每一个关键词作为语义空间中的一个维度来构建空间；而描述嵌入空间则通过一些学习模型来构建语义空间。这些模型的输入输出分别为文本描述和类原型。 ​ 在图像识别任务中，我们可以为每一张图收集一些文本描述。通过文本嵌入模型，我们可以将这些文本描述转化为对应的类原型，用于辅助识别可能出现的未知类。 优劣分析 人工干预式语义空间的优点是可以通过人为构造语义空间和类原型来灵活地利用人类的知识。缺点是该方法对人的依赖性过大，需要付出巨大的成本来完成语义空间的设计与构造； 机器学习的语义空间的优势则在于它们的生成过程相对省力，且生成的语义空间中包含有容易被人忽视的信息。缺点在于这类方法生成的空间，其每个维度的语义对人类而言是难以理解的，是隐性的。 零样本学习方法 现有的零样本学习方法可以分为两类，一类是基于分类器的方法，一类是基于实例的方法。 ​ 基于分类器的方法的重点在于如何直接为未知类学习分类器； ​ 基于实例的方法的重心则在于如何获取属于未知类的标记实例，并利用这些实例学习对应的分类器。 基于分类器的方法 根据构造分类器的方法，基于分类器的方法可以被进一步分为三个子类： 对应方法 关系方法 组合方法 ​ 现有的基于分类器的方法通常采用一对多（one-versus-rest）方法类学习多类别零样本学习，即，对于每个未知类，都将学习一个二分类的一对多分类器。 对应方法 关系方法 组合方法 基于实例的方法 这种方法首先为未知类获取标记实例，然后使用这些实例来学习零样本分类器。根据这些实例的来源，现有的方法可以被分为三个子类： 投影方法 借用方法 综合方法 投影方法 借用方法 综合方法 讨论与发散 优劣分析 多标签零样本学习 广义零样本学习 ","link":"https://Yhaoze.github.io/post/summary2020zero-shot-learning-settings-methods-and-applications/"},{"title":"[Paper][NAACL-2019]HiGRU: Hierarchical Gated Recurrent Units for Utterance-level Emotion Recognition","content":"Overview 应用场景：对话模型中的情感识别 解决问题： 相同的单词在不同的上下文语境中可以传递不同的情感； 在一般对话中很少见到某些强烈的情绪情感； 很难有效地获取远程上下文信息。 主要贡献： 提出了HiGRU框架，能够更准确地学习语句的嵌入信息，并据此识别情感； 提出了两种渐进式的HiGRU变体——HiGRU-f和HiGRU-sf，分别融合各个单词、话语级别的信息和长时上下文信息。 数据来源： IEMOCAP：它包含了大约12个小时的视听数据，包括视频、语音、面部动作捕捉和文本转录内容，含有四种情感标签。 FRIENDS：来自“老友记”的对话（及标注），包含八种情感标签（但进选取四个训练）。 EmotionPush: 这个数据集中包含了1000个Facebook上的私人对话，包含有和FRIENDS相同的八种情感标签（同样只选取四个训练）。 Model HiGRU（上图出去两个虚线框后的模型结构）: 主体结构分为两层，网络下层为左半边模型，在得到文本、话语的词嵌入（字嵌入）后，通过BiGRU网络（激励函数为tanh函数）获取句嵌入；网络上层为右半边模型，在得到句嵌入后，通过相似的结构（BiGRU）获得基于上下文信息的句嵌入，此后，一次通过全连接层和Softmax函数得到最终的情感分类。 HiGRU-f（HiGRU+Fusion层）：在HiGRU结构的基础上又添加了Fusion层。Fusion层的作用是将各输入（下层网络中的词嵌入和上层网络中的句嵌入）与BiGRU结构的隐藏状态（hforwardh_{forward}hforward​和hbackwardh_{backward}hbackward​）输出连接起来作为BiGRU结构的整体隐藏层。 HiGRU-sf（HiGRU+Fusion+Attention）：在HiGRU结构的基础上又添加了Fusion层和Attention层，Fusion层同HiGRU-f，Attention层为自注意力层（self-attention），示意图如下： 其中： Experiment 验证了在IEMOCAP数据集上，HiGRU及两个变体都取得了更好的情感分类效果： 验证了在FRIENDS和EmotionPush数据集上能得到更好的效果，且训练集不同，结果各有差异： （F代表只在FRIENDS数据集上训练，E代表只在EmotionPush数据集上训练，F+E代表两者共同作为训练集） ","link":"https://Yhaoze.github.io/post/papernaacl-2019higru-hierarchical-gated-recurrent-units-for-utterance-level-emotion-recognition/"},{"title":"[Paper][NAACL-2019]Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis","content":"Overview 应用场景：多种不同的信息输入（如：文本、音频、视频信息）情况下的情感识别 主要贡献： 利用有效的多模式框架，将两个相关任务（即情感识别和情绪分类任务）的相互依存关系改善结果； 提出了语境间（inter-modal）注意力机制，该机制有助于模型同时为做出贡献的语境话语和/或语气分配权重； 提供了“最先进的”（文章自称）情感识别和情绪分类方法。 数据来源：CMU Multi-modal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) dataset ​ 这个数据集包含了文本、音频、视频三种不同模式的输入。 Model embedding: Text - GloVe; Visual - Facets; Acoustic - CovaRap. 主模型：三种不同模式的输入信息分别通过三个BiGRU网络得到三个不同的特征矩阵，接着由CIM-Attention层学习模式两两之间的关联情况，最后分别通过softmax层（情感识别）和sigmoid层（情绪分类）得到最终的结果。 CIM-Attention: Experiment 验证了多任务模型会比单任务模型具有更好的效果： 对CIM-Attention的attention weights做了可视化处理，帮助解释模型的工作原理： ","link":"https://Yhaoze.github.io/post/papernaacl-2019multi-task-learning-for-multi-modal-emotion-recognition-and-sentiment-analysis/"},{"title":"[Paper][EMNLP-2019]Multi-label Categorization of Accounts of Sexism using a Neural Framework","content":"Overview 应用场景：网络上关于性别歧视内容的识别与分类 数据来源：Everyday Sexism Project website中的13023个条目，并由10名注释人员标注标签 嵌入模型： 词嵌入： ELMo (Embeddings from Language Models) GloVe (Global Vectors) fastText 句嵌入： BERT (Bidirectional Encoder Representations from Transformers) USE (Universal Sentence Encoder) InferSent 贡献： 提出了一个用于性别歧视问题的、多标签分类的神经框架 对任何类型的性别歧视问题进行了考虑 提供了一个包括13023个性别歧视说明的数据集，并制定了23种性别歧视类别 Model word embedding部分为多个不同的词嵌入模块共同组成； sentence embedding部分为多个不同的句嵌入模块组成； configurable word-level concatenated部分是通过不同的词嵌入模块得到的嵌入向量组合得到的不同结果； configurable sentence-level concatenated部分是通过不同句嵌入模块得到的嵌入向量和通过CNN/biLSTM学习得到的词嵌入的特征向量组合得到的不同结果。 loss函数部分：由于交叉熵函数不适合多标签的分类任务，提供了两个变种。 EBCE: EBCE weight: NCE: NCE weight: Experiment 验证了传统的机器学习算法在多标签任务中的短板： 检验了不同的模型结构（CNN/biLSTM; word embedding/sentence embedding; EBCE loss/NCE loss）对结果的影响: ","link":"https://Yhaoze.github.io/post/paperemnlp-2019multi-label-categorization-of-accounts-of-sexism-using-a-neural-framework/"}]}
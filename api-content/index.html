{"posts":[{"title":"[Paper][NAACL-2019]HiGRU: Hierarchical Gated Recurrent Units for Utterance-level Emotion Recognition","content":"Overview 应用场景：对话模型中的情感识别 解决问题： 相同的单词在不同的上下文语境中可以传递不同的情感； 在一般对话中很少见到某些强烈的情绪情感； 很难有效地获取远程上下文信息。 主要贡献： 提出了HiGRU框架，能够更准确地学习语句的嵌入信息，并据此识别情感； 提出了两种渐进式的HiGRU变体——HiGRU-f和HiGRU-sf，分别融合各个单词、话语级别的信息和长时上下文信息。 数据来源： IEMOCAP：它包含了大约12个小时的视听数据，包括视频、语音、面部动作捕捉和文本转录内容，含有四种情感标签。 FRIENDS：来自“老友记”的对话（及标注），包含八种情感标签（但进选取四个训练）。 EmotionPush: 这个数据集中包含了1000个Facebook上的私人对话，包含有和FRIENDS相同的八种情感标签（同样只选取四个训练）。 Model HiGRU（上图出去两个虚线框后的模型结构）: 主体结构分为两层，网络下层为左半边模型，在得到文本、话语的词嵌入（字嵌入）后，通过BiGRU网络（激励函数为tanh函数）获取句嵌入；网络上层为右半边模型，在得到句嵌入后，通过相似的结构（BiGRU）获得基于上下文信息的句嵌入，此后，一次通过全连接层和Softmax函数得到最终的情感分类。 HiGRU-f（HiGRU+Fusion层）：在HiGRU结构的基础上又添加了Fusion层。Fusion层的作用是将各输入（下层网络中的词嵌入和上层网络中的句嵌入）与BiGRU结构的隐藏状态（hforwardh_{forward}hforward​和hbackwardh_{backward}hbackward​）输出连接起来作为BiGRU结构的整体隐藏层。 HiGRU-sf（HiGRU+Fusion+Attention）：在HiGRU结构的基础上又添加了Fusion层和Attention层，Fusion层同HiGRU-f，Attention层为自注意力层（self-attention），示意图如下： 其中： Experiment 验证了在IEMOCAP数据集上，HiGRU及两个变体都取得了更好的情感分类效果： 验证了在FRIENDS和EmotionPush数据集上能得到更好的效果，且训练集不同，结果各有差异： （F代表只在FRIENDS数据集上训练，E代表只在EmotionPush数据集上训练，F+E代表两者共同作为训练集） ","link":"https://Yhaoze.github.io/post/papernaacl-2019higru-hierarchical-gated-recurrent-units-for-utterance-level-emotion-recognition/"},{"title":"[Paper][NAACL-2019]Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis","content":"Overview 应用场景：多种不同的信息输入（如：文本、音频、视频信息）情况下的情感识别 主要贡献： 利用有效的多模式框架，将两个相关任务（即情感识别和情绪分类任务）的相互依存关系改善结果； 提出了语境间（inter-modal）注意力机制，该机制有助于模型同时为做出贡献的语境话语和/或语气分配权重； 提供了“最先进的”（文章自称）情感识别和情绪分类方法。 数据来源：CMU Multi-modal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) dataset ​ 这个数据集包含了文本、音频、视频三种不同模式的输入。 Model embedding: Text - GloVe; Visual - Facets; Acoustic - CovaRap. 主模型：三种不同模式的输入信息分别通过三个BiGRU网络得到三个不同的特征矩阵，接着由CIM-Attention层学习模式两两之间的关联情况，最后分别通过softmax层（情感识别）和sigmoid层（情绪分类）得到最终的结果。 CIM-Attention: Experiment 验证了多任务模型会比单任务模型具有更好的效果： 对CIM-Attention的attention weights做了可视化处理，帮助解释模型的工作原理： ","link":"https://Yhaoze.github.io/post/papernaacl-2019multi-task-learning-for-multi-modal-emotion-recognition-and-sentiment-analysis/"},{"title":"[Paper][EMNLP-2019]Multi-label Categorization of Accounts of Sexism using a Neural Framework","content":"Overview 应用场景：网络上关于性别歧视内容的识别与分类 数据来源：Everyday Sexism Project website中的13023个条目，并由10名注释人员标注标签 嵌入模型： 词嵌入： ELMo (Embeddings from Language Models) GloVe (Global Vectors) fastText 句嵌入： BERT (Bidirectional Encoder Representations from Transformers) USE (Universal Sentence Encoder) InferSent 贡献： 提出了一个用于性别歧视问题的、多标签分类的神经框架 对任何类型的性别歧视问题进行了考虑 提供了一个包括13023个性别歧视说明的数据集，并制定了23种性别歧视类别 Model word embedding部分为多个不同的词嵌入模块共同组成； sentence embedding部分为多个不同的句嵌入模块组成； configurable word-level concatenated部分是通过不同的词嵌入模块得到的嵌入向量组合得到的不同结果； configurable sentence-level concatenated部分是通过不同句嵌入模块得到的嵌入向量和通过CNN/biLSTM学习得到的词嵌入的特征向量组合得到的不同结果。 loss函数部分：由于交叉熵函数不适合多标签的分类任务，提供了两个变种。 EBCE: EBCE weight: NCE: NCE weight: Experiment 验证了传统的机器学习算法在多标签任务中的短板： 检验了不同的模型结构（CNN/biLSTM; word embedding/sentence embedding; EBCE loss/NCE loss）对结果的影响: ","link":"https://Yhaoze.github.io/post/paperemnlp-2019multi-label-categorization-of-accounts-of-sexism-using-a-neural-framework/"}]}
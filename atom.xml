<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Yhaoze.github.io</id>
    <title>Yhaoze&apos;s blog</title>
    <updated>2020-06-06T11:57:03.425Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Yhaoze.github.io"/>
    <link rel="self" href="https://Yhaoze.github.io/atom.xml"/>
    <subtitle>吾尝终日而思矣，不如须臾之所学也</subtitle>
    <logo>https://Yhaoze.github.io/images/avatar.png</logo>
    <icon>https://Yhaoze.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, Yhaoze&apos;s blog</rights>
    <entry>
        <title type="html"><![CDATA[[Paper][NAACL-2019]Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis]]></title>
        <id>https://Yhaoze.github.io/post/papernaacl-2019multi-task-learning-for-multi-modal-emotion-recognition-and-sentiment-analysis/</id>
        <link href="https://Yhaoze.github.io/post/papernaacl-2019multi-task-learning-for-multi-modal-emotion-recognition-and-sentiment-analysis/">
        </link>
        <updated>2020-06-06T11:11:28.000Z</updated>
        <content type="html"><![CDATA[<h1 id="overview">Overview</h1>
<ul>
<li>
<p>应用场景：多种不同的信息输入（如：文本、音频、视频信息）情况下的情感识别</p>
</li>
<li>
<p>只要贡献：</p>
<ul>
<li>利用有效的多模式框架，将两个相关任务（即情感识别和情绪分类任务）的相互依存关系改善结果；</li>
<li>提出了语境间（inter-modal）注意力机制，该机制有助于模型同时为做出贡献的语境话语和/或语气分配权重；</li>
<li>提供了“最先进的”（文章自称）情感识别和情绪分类方法。</li>
</ul>
</li>
<li>
<p>数据来源：CMU Multi-modal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) dataset</p>
<p>​	这个数据集包含了文本、音频、视频三种不同模式的输入。</p>
</li>
</ul>
<h1 id="model">Model</h1>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper2_model.png" width="600px" />
<ul>
<li>
<p>embedding: Text - GloVe; Visual - Facets; Acoustic - CovaRap.</p>
</li>
<li>
<p>主模型：三种不同模式的输入信息分别通过三个BiGRU网络得到三个不同的特征矩阵，接着由CIM-Attention层学习模式两两之间的关联情况，最后分别通过softmax层（情感识别）和sigmoid层（情绪分类）得到最终的结果。</p>
</li>
<li>
<p>CIM-Attention:</p>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper2_CIM-Attention.jpg" width="300px" />
</li>
</ul>
<h1 id="experiment">Experiment</h1>
<ul>
<li>验证了多任务模型会比单任务模型具有更好的效果：</li>
</ul>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper2_experiment_1.jpg" width="700px" />
<ul>
<li>对CIM-Attention的attention weights做了可视化处理，帮助解释模型的工作原理：</li>
</ul>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper2_experiment_2.jpg" width="700px" />]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[[Paper][EMNLP-2019]Multi-label Categorization of Accounts of Sexism using a Neural Framework]]></title>
        <id>https://Yhaoze.github.io/post/paperemnlp-2019multi-label-categorization-of-accounts-of-sexism-using-a-neural-framework/</id>
        <link href="https://Yhaoze.github.io/post/paperemnlp-2019multi-label-categorization-of-accounts-of-sexism-using-a-neural-framework/">
        </link>
        <updated>2020-05-29T04:57:36.000Z</updated>
        <content type="html"><![CDATA[<h1 id="overview">Overview</h1>
<ul>
<li>
<p>应用场景：网络上关于性别歧视内容的识别与分类</p>
</li>
<li>
<p>数据来源：Everyday Sexism Project website中的13023个条目，并由10名注释人员标注标签</p>
</li>
<li>
<p>嵌入模型：</p>
<ul>
<li>
<p>词嵌入：</p>
<ul>
<li>ELMo (Embeddings from Language Models)</li>
<li>GloVe (Global Vectors)</li>
<li>fastText</li>
</ul>
</li>
<li>
<p>句嵌入：</p>
<ul>
<li>BERT (Bidirectional Encoder Representations from Transformers)</li>
<li>USE (Universal Sentence Encoder)</li>
<li>InferSent</li>
</ul>
</li>
</ul>
</li>
<li>
<p>贡献：</p>
<ul>
<li>提出了一个用于性别歧视问题的、多标签分类的神经框架</li>
<li>对任何类型的性别歧视问题进行了考虑</li>
<li>提供了一个包括13023个性别歧视说明的数据集，并制定了23种性别歧视类别</li>
</ul>
</li>
</ul>
<h1 id="model">Model</h1>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_model.png" width="600px" />
<ul>
<li>word embedding部分为多个不同的词嵌入模块共同组成；</li>
<li>sentence embedding部分为多个不同的句嵌入模块组成；</li>
<li>configurable word-level concatenated部分是通过不同的词嵌入模块得到的嵌入向量组合得到的不同结果；</li>
<li>configurable sentence-level concatenated部分是通过不同句嵌入模块得到的嵌入向量和通过CNN/biLSTM学习得到的词嵌入的特征向量组合得到的不同结果。</li>
<li>loss函数部分：由于交叉熵函数不适合多标签的分类任务，提供了两个变种。
<ul>
<li>EBCE:<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_loss_EBCE.jpg" width="300px" /></li>
<li>EBCE weight:<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_loss_EBCE_weight.jpg" width="300px" /></li>
<li>NCE: <img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_loss_NCE.jpg" width="300px" /></li>
<li>NCE weight:<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_loss_NCE_weight.png" width="150px" /></li>
</ul>
</li>
</ul>
<h1 id="experiment">Experiment</h1>
<ul>
<li>
<p>验证了传统的机器学习算法在多标签任务中的短板：</p>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_experiment_1.png" width="800px" />
</li>
<li>
<p>检验了不同的模型结构（CNN/biLSTM; word embedding/sentence embedding; EBCE loss/NCE loss）对结果的影响:</p>
<img src="https://raw.githubusercontent.com/Yhaoze/Picbed/master/paper1_experiment_2.png" width="500px" /></li>
</ul>
]]></content>
    </entry>
</feed>